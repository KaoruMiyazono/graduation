import os
import numpy as np
import torch 
import random
from scipy import interpolate
from tqdm import tqdm
import re
from collections import defaultdict
# from process_widar import Intel
import matplotlib.pyplot as plt
import json

def average_list(d_list):
    '''
    Args:
        d_list (list): shape [T,90]

    '''
    sum = [0.0 for _ in range(len(d_list[0]))] # for each channel
    for j in range(len(d_list[0])):
        for i in range(len(d_list)):
            sum[j] += d_list[i][j]
        sum[j] /= len(d_list)
    return sum

def merge_timestamp(data, time_stamp, new_length = 2000):
    """align each samples time length

    Args:
        data (ndarray): input signal list with shape [T,90]
        time_stamp (list): corresponding time stamp 

    Returns:
        aligned_data(list): list whose elements have the same length
    """
    intervel = (time_stamp[len(time_stamp)-1] - time_stamp[0]) / new_length
    cur_range = time_stamp[0] + intervel
    temp_list = []
    align_data = []
    for i in range(len(time_stamp)):
        if time_stamp[i] > cur_range:
            if len(temp_list) != 0:
                align_data.append(average_list(temp_list))
            else:
                align_data.append(data[i])
            temp_list = []
            cur_range = cur_range + intervel
        temp_list.append(data[i])
    if len(temp_list) != 0:
        align_data.append(average_list(temp_list))
    if len(align_data) < new_length:
        align_data.append(data[len(time_stamp)-1])
        print("shorter than new_length, add the last element")
    return align_data[:new_length]

def resample(signal,time_stamp,newtimelen):
    """
        upsample or downsample the signal to target length
    Args:
        signal: Original signal
        time_stamp:time_stamp of the original signal
        newtimelen: the target time length
    """
    current_time_len = len(signal)
    # upsample
    if current_time_len<newtimelen:
        return upsample(signal,time_stamp,newtimelen)

    # no action
    if current_time_len == newtimelen:
        return signal

    # downsample
    if current_time_len>newtimelen:
        return merge_timestamp(signal,time_stamp,newtimelen)
    

def upsample(signal,time_stamp,newtimelen):
    '''
    æ ¹æ®è¿™ä¸ªä½ç½®åœ¨ä¸¤ä¸ªstampä¹‹é—´çš„æ¯”ä¾‹è¿›è¡Œæ’å€¼
    TODO æ¯”è¾ƒç›´æ¥ç”Ÿæˆæ—¶é—´è½´ç„¶åç”¨npçš„æ’å€¼å‡½æ•°å’Œè‡ªå·±é€ä¸ªæ’å€¼ä¹‹é—´æ—¶é—´åŒºåˆ«
    '''
    # éœ€è¦require_new_time_stampä¸ªå…ƒç´ ,é‚£ä¹ˆä¸­é—´çš„é—´éš”å°±éœ€è¦require_new_time_stamp+1ä¸ª
    require_new_time_stamp = newtimelen-len(time_stamp)
    interval = (time_stamp[-1] - time_stamp[0]) / (require_new_time_stamp+1)
    new_time_stamp = np.zeros(newtimelen)
    new_time_stamp[0] = time_stamp[0]
    #new_time_stamp[-1] = time_stamp[-1]
    current_timestamp = time_stamp[0]
    origin_time_index = 1
    new_time_index = 1
    while new_time_index<newtimelen:
        current_timestamp = current_timestamp+interval
        while current_timestamp>= time_stamp[origin_time_index] and origin_time_index<len(time_stamp)-1: 
            #ä¸€ç›´å¾€åé¢æœç´¢ï¼Œä¿è¯å½“å½“å‰newtimestampå†…çš„æ‰€æœ‰oritimestampå…¨éƒ¨è¢«ä¿ç•™
            new_time_stamp[new_time_index] = time_stamp[origin_time_index]
            origin_time_index+=1  #å¢åŠ oritimesampç›´è‡³å¤§äºcurrent_timestamp
            new_time_index +=1    
        # if current_timestamp >time_stamp[-1]:#ä¸å¤ªå¯èƒ½çš„æƒ…å†µæ˜¯current_timestampå¤§äºoritimestampçš„æœ€ç»ˆå€¼
        #     current_timestamp = (new_time_stamp[new_time_index-1]+time_stamp[-1])/2      
        new_time_stamp[new_time_index] = current_timestamp
        new_time_index+=1
    #print(signal.shape) # T C
    f = interpolate.interp1d(time_stamp, signal,axis=0)
    new_time_stamp = np.clip(new_time_stamp, np.min(time_stamp), np.max(time_stamp)) #æˆ‘å®¶çš„  å¯èƒ½ä¸å¯¹
    return f(new_time_stamp) 

def rename_widar_files(folder_path):
    """
    æ‰«ææŒ‡å®šæ–‡ä»¶å¤¹ï¼Œå°†æ–‡ä»¶åä» 'room_X_user_userY_ges_A_loc_B_ori_C_rx_rD.npy' 
    ä¿®æ”¹ä¸º 'room_X_user_Y_ges_A_loc_B_ori_C_rx_D.npy'ã€‚
    
    :param folder_path: éœ€è¦é‡å‘½åæ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„
    """
    if not os.path.exists(folder_path):
        print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}")
        return

    files_renamed = 0
    
    for filename in os.listdir(folder_path):
        old_path = os.path.join(folder_path, filename)
        
        # åªå¤„ç† .npy æ–‡ä»¶
        if filename.endswith(".npy"):
            new_filename = re.sub(r"user_user(\d+)", r"user_\1", filename)  # user_userX -> user_X
            new_filename = re.sub(r"rx_r(\d+)", r"rx_\1", new_filename)  # rx_rX -> rx_X
            
            new_path = os.path.join(folder_path, new_filename)
            
            # åªæœ‰å½“æ–‡ä»¶åå‘ç”Ÿå˜åŒ–æ—¶æ‰é‡å‘½å
            if old_path != new_path:
                os.rename(old_path, new_path)
                print(f"âœ… é‡å‘½å: {filename} -> {new_filename}")
                files_renamed += 1
    
    if files_renamed == 0:
        print("âš ï¸ æ²¡æœ‰éœ€è¦é‡å‘½åçš„æ–‡ä»¶ã€‚")
    else:
        print(f"ğŸ‰ å…±é‡å‘½å {files_renamed} ä¸ªæ–‡ä»¶ã€‚")

def count_files_in_folder(folder_path):
    """
    ç»Ÿè®¡æŒ‡å®šæ–‡ä»¶å¤¹å†…çš„æ–‡ä»¶æ•°é‡ï¼ˆä¸åŒ…æ‹¬å­æ–‡ä»¶å¤¹ï¼‰ã€‚
    
    :param folder_path: æ–‡ä»¶å¤¹è·¯å¾„
    :return: æ–‡ä»¶æ•°é‡
    """
    if not os.path.exists(folder_path):
        print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}")
        return 0

    file_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])
    
    print(f"ğŸ“‚ æ–‡ä»¶å¤¹ {folder_path} å†…å…±æœ‰ {file_count} ä¸ªæ–‡ä»¶ã€‚")
    return file_count


def count_files_by_user(folder_path):
    """
    ç»Ÿè®¡æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹æ¯ä¸ª user å¯¹åº”çš„æ–‡ä»¶æ•°é‡ã€‚
    
    :param folder_path: æ–‡ä»¶å¤¹è·¯å¾„
    :return: ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«æ¯ä¸ª user å’Œå¯¹åº”çš„æ–‡ä»¶æ•°é‡
    """
    if not os.path.exists(folder_path):
        print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}")
        return {}
    
    user_file_count = defaultdict(int)  # ç”¨æ¥å­˜å‚¨æ¯ä¸ª user å¯¹åº”çš„æ–‡ä»¶æ•°é‡
    
    for filename in os.listdir(folder_path):
        file_path = os.path.join(folder_path, filename)
        
        # åªç»Ÿè®¡æ–‡ä»¶ï¼Œä¸ç»Ÿè®¡å­æ–‡ä»¶å¤¹
        if os.path.isfile(file_path):
            # å‡è®¾æ–‡ä»¶åä¸­æœ‰ 'user_X' æ ¼å¼ï¼Œé€šè¿‡æ­£åˆ™è¡¨è¾¾å¼æå– 'user_X'
            if 'user_' in filename:
                user_match = filename.split('user_')[-1].split('_')[0]  # æå– 'user_X'
                user_file_count[user_match] += 1
    
    if user_file_count:
        print("æ¯ä¸ª user çš„æ–‡ä»¶æ•°é‡ï¼š")
        for user, count in user_file_count.items():
            print(f"user_{user}: {count} ä¸ªæ–‡ä»¶")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶ã€‚")
    
    return user_file_count


# def count_files_by_user(folder_path, target_user='3'):
#     """
#     ç»Ÿè®¡æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹æ¯ä¸ª user å¯¹åº”çš„æ–‡ä»¶æ•°é‡ï¼Œå¹¶å¯æ‰“å°æŒ‡å®š user çš„æ–‡ä»¶åˆ—è¡¨ã€‚
    
#     :param folder_path: æ–‡ä»¶å¤¹è·¯å¾„
#     :param target_user: éœ€è¦æŸ¥çœ‹çš„ç”¨æˆ·ï¼ˆä¾‹å¦‚ 'user_3'ï¼‰ï¼Œå¦‚æœä¸º None åˆ™æ‰“å°æ‰€æœ‰ç”¨æˆ·çš„æ–‡ä»¶æ•°é‡
#     :return: ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«æ¯ä¸ª user å’Œå¯¹åº”çš„æ–‡ä»¶æ•°é‡
#     """
#     if not os.path.exists(folder_path):
#         print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}")
#         return {}
    
#     user_file_count = defaultdict(list)  # ç”¨æ¥å­˜å‚¨æ¯ä¸ª user å¯¹åº”çš„æ–‡ä»¶åˆ—è¡¨
    
#     for filename in os.listdir(folder_path):
#         file_path = os.path.join(folder_path, filename)
        
#         # åªç»Ÿè®¡æ–‡ä»¶ï¼Œä¸ç»Ÿè®¡å­æ–‡ä»¶å¤¹
#         if os.path.isfile(file_path):
#             # å‡è®¾æ–‡ä»¶åä¸­æœ‰ 'user_X' æ ¼å¼ï¼Œé€šè¿‡æ­£åˆ™è¡¨è¾¾å¼æå– 'user_X'
#             if 'user_' in filename:
#                 user_match = filename.split('user_')[-1].split('_')[0]  # æå– 'user_X'
#                 user_file_count[user_match].append(filename)
    
#     if target_user:
#         if target_user in user_file_count:
#             print(f"{target_user} çš„æ–‡ä»¶åˆ—è¡¨ï¼š")
#             for file in user_file_count[target_user]:
#                 print(file)
#         else:
#             print(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ° {target_user} çš„æ–‡ä»¶ã€‚")
    
#     else:
#         print("æ¯ä¸ª user çš„æ–‡ä»¶æ•°é‡ï¼š")
#         for user, files in user_file_count.items():
#             print(f"user_{user}: {len(files)} ä¸ªæ–‡ä»¶")
    
#     return user_file_count


def count_files_by_conditions(folder_path, room, loc, ori, target_user=None):
    """
    ç»Ÿè®¡æŒ‡å®šæ–‡ä»¶å¤¹ä¸‹ï¼Œç¬¦åˆæŒ‡å®šæ¡ä»¶ï¼ˆå¦‚ room, loc, ori å’Œ userï¼‰çš„æ–‡ä»¶æ•°é‡ã€‚
    
    :param folder_path: æ–‡ä»¶å¤¹è·¯å¾„
    :param room: è¦æŸ¥è¯¢çš„ roomï¼Œå¦‚ 'room_1'
    :param loc: è¦æŸ¥è¯¢çš„ locï¼Œå¦‚ 'loc_1'
    :param ori: è¦æŸ¥è¯¢çš„ oriï¼Œå¦‚ 'ori_1'
    :param target_user: éœ€è¦æŸ¥çœ‹çš„ç”¨æˆ·ï¼ˆä¾‹å¦‚ 'user_3'ï¼‰ï¼Œå¦‚æœä¸º None åˆ™ä¸é™åˆ¶ user
    :return: ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶åˆ—è¡¨
    """
    if not os.path.exists(folder_path):
        print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}")
        return []
    
    matched_files = []
    
    for filename in os.listdir(folder_path):
        file_path = os.path.join(folder_path, filename)
        
        # åªç»Ÿè®¡æ–‡ä»¶ï¼Œä¸ç»Ÿè®¡å­æ–‡ä»¶å¤¹
        if os.path.isfile(file_path):
            # è¿‡æ»¤æ–‡ä»¶åä¸­åŒ…å«æŒ‡å®šæ¡ä»¶çš„æ–‡ä»¶
            if room in filename and loc in filename and ori in filename:
                # å¦‚æœæŒ‡å®šäº† target_userï¼Œä¹Ÿè¦æ£€æŸ¥æ˜¯å¦ç¬¦åˆ user_3 æ ¼å¼
                if target_user and f"user_{target_user}" in filename:
                    matched_files.append(filename)
                # å¦‚æœæ²¡æœ‰æŒ‡å®š userï¼Œç›´æ¥ç¬¦åˆå…¶ä»–æ¡ä»¶çš„æ–‡ä»¶ä¹ŸåŠ å…¥
                elif not target_user:
                    matched_files.append(filename)
    
    if matched_files:
        print(f"ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶æ•°é‡ï¼š{len(matched_files)} ä¸ªæ–‡ä»¶")
        for file in matched_files:
            print(file)
    else:
        print(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶ã€‚")
    
    return matched_files


def plot_csi_length_distribution(len_list, save_path="csi_length_distribution.png"):
    """
    æ ¹æ® CSI é•¿åº¦åˆ†å¸ƒç»˜åˆ¶ç›´æ–¹å›¾ï¼Œå¹¶è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    :param len_list: å­˜å‚¨æ¯ä¸ªæ ·æœ¬ CSI é•¿åº¦çš„åˆ—è¡¨
    :param save_path: ä¿å­˜å›¾ç‰‡çš„è·¯å¾„
    """
    len_list = np.array(len_list)
    bins = np.arange(0, max(len_list) + 100, 100)

    mean_val = np.mean(len_list)
    max_val = np.max(len_list)
    min_val = np.min(len_list)
    median_val = np.median(len_list)

    plt.figure(figsize=(10, 5))
    plt.hist(len_list, bins=bins, edgecolor='black', alpha=0.7)
    plt.xlabel("CSI Length (æ¯ 100 ä¸€ä¸ªåŒºé—´)")
    plt.ylabel("æ ·æœ¬æ•°é‡")
    plt.title("CSI é•¿åº¦åˆ†å¸ƒ")
    plt.grid(axis='y', linestyle='--', alpha=0.7)

    text_str = f"å‡å€¼: {mean_val:.2f}\næœ€å¤§å€¼: {max_val}\næœ€å°å€¼: {min_val}\nä¸­ä½æ•°: {median_val}"
    plt.text(0.7 * max(len_list), max(plt.hist(len_list, bins=bins)[0]) * 0.7, text_str, fontsize=12,
             bbox=dict(facecolor='white', alpha=0.5))

    # **ä¿å­˜å›¾ç‰‡**
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"å›¾åƒå·²ä¿å­˜ä¸º {save_path}")

    plt.show()

    return {"mean": mean_val, "max": max_val, "min": min_val, "median": median_val}


# def get_widar_length_distribution(file_path):
#      len_list=[]
#      cnt=0
#      with open(file_path, 'r') as f:
#         for line in f:
#             line = line.rstrip()
#             # print(line)
            
#             widar_data_single=Intel(file=line,nrxnum=3, ntxnum=1, pl_len=0, if_report=True)
#             widar_data_single.read()
#             csi=widar_data_single.get_scaled_csi()
#             len_list.append(csi.shape[0])
#             cnt=cnt+1
#             print(cnt)
#         return len_list





